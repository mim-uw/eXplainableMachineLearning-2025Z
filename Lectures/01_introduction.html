<!DOCTYPE html>
<html lang="en"><head>
<script src="01_introduction_files/libs/clipboard/clipboard.min.js"></script>
<script src="01_introduction_files/libs/quarto-html/tabby.min.js"></script>
<script src="01_introduction_files/libs/quarto-html/popper.min.js"></script>
<script src="01_introduction_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="01_introduction_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="01_introduction_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="01_introduction_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="01_introduction_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.450">

  <meta name="author" content="Przemysław Biecek">
  <meta name="dcterms.date" content="2025-10-03">
  <title>Introduction</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="01_introduction_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="01_introduction_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="01_introduction_files/libs/revealjs/dist/theme/quarto.css">
  <link href="01_introduction_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="01_introduction_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Introduction</h1>
  <p class="subtitle">eXplainable Machine Learning / Model Science</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Przemysław Biecek 
</div>
</div>
</div>

  <p class="date">2025-10-03</p>
</section>
<section>
<section id="design-principles" class="title-slide slide level1 center">
<h1>Design Principles</h1>

</section>
<section id="what-is-this-course-for" class="slide level2">
<h2>What is this course for?</h2>

<img data-src="images/01_break_l.png" class="r-stretch"></section>
<section id="what-is-this-course-for-1" class="slide level2">
<h2>What is this course for?</h2>

<img data-src="images/01_break.png" class="r-stretch"></section>
<section id="about-us" class="slide level2">
<h2>About us</h2>
<div class="columns">
<div class="column" style="width:67%;">
<p><strong>Przemysław Biecek</strong></p>
<ul>
<li>works at <em>Faculty of Mathematics, Informatics, and Mechanics</em> at University of Warsaw and <em>Faculty of Mathematics and Information Science</em> at Warsaw University of Technology</li>
<li>research interests include Responsible Machine Learning and eXplainable Artificial Intelligence (Model Science)</li>
<li>worked in R&amp;D teams at large and small corporations such as Samsung, IBM, Netezza, Disney, iQuor</li>
<li>leads the MI2.AI research team, which carries out XAI related research projects under NCN, NCBiR, FNP programmes</li>
<li>this is my seventh edition of classes about XAI</li>
</ul>
</div><div class="column" style="width:33%;">
<p><img data-src="images/01_przemek.png"></p>
</div>
</div>
</section>
<section id="about-us-1" class="slide level2">
<h2>About us</h2>
<div class="columns">
<div class="column" style="width:67%;">
<p><strong>Bartłomiej Sobieski</strong></p>
<ul>
<li>PhD student in CS/AI at the University of Warsaw, Deep Learning Researcher at MI2.AI</li>
<li>BSc degree in Mathematics and Data Analysis, MSc degree in Data Science at Warsaw University of Technology</li>
<li>XAI + image generative modeling = :heart:</li>
<li>I like math</li>
</ul>
</div><div class="column" style="width:33%;">
<p><img data-src="images/01_bsobieski.jpeg"></p>
</div>
</div>
</section>
<section id="class-participants" class="slide level2">
<h2>Class participants</h2>
<p>Let’s get to know each other!</p>
<p><br></p>

<img data-src="images/01_menti.png" class="r-stretch"></section>
<section id="how-it-looked-in-the-past-13" class="slide level2">
<h2>How it looked in the past 1/3</h2>
<p>Edition 2022/23: <a href="https://github.com/MI2-Education/InterpretableMachineLearning2022">https://github.com/MI2-Education/InterpretableMachineLearning2022</a></p>
<ul>
<li>Projects related to applications of XAI techniques to the real world problems in collaboration with business partners.</li>
<li>7 lectures + projects + homeworks + presentations</li>
</ul>
<p>
<img src="images/01_xai_stories.png" width="80%">
</p>
<!-- ![prev editions](images/xai_stories.png) -->
<p><strong>Example stories:</strong></p>
<ul>
<li><a href="https://pbiecek.github.io/xai_stories/story-house-sale-prices.html">https://pbiecek.github.io/xai_stories/story-house-sale-prices.html</a></li>
<li><a href="https://pbiecek.github.io/xai_stories_2/story-seasonal-products.html">https://pbiecek.github.io/xai_stories_2/story-seasonal-products.html</a></li>
<li><a href="https://pbiecek.github.io/xai_stories_2/story-bert-in-the-recommendation-system.html">https://pbiecek.github.io/xai_stories_2/story-bert-in-the-recommendation-system.html</a></li>
</ul>
<p><strong>Comments after previous editions:</strong></p>
<ul>
<li>Business applications are cool, but there is a lot of interest in research projects</li>
<li>Systematic work, especially in the first half of the semester is good, and avoids piling up issues at the end of the semester</li>
<li>Emphasis on commenting on the results, focusing on interpretation is very valuable (although time consuming)</li>
<li>It would be great to have more lectures (than 7) in order to discuss techniques specific to certain modalities, such as computer vision and NLP</li>
</ul>
</section>
<section id="how-it-looked-in-the-past-23" class="slide level2">
<h2>How it looked in the past 2/3</h2>
<p>Edition 2023/24: <a href="https://github.com/MI2-Education/InterpretableMachineLearning2024">https://github.com/MI2-Education/InterpretableMachineLearning2024</a></p>
<p>Reports: <a href="https://modeloriented.github.io/CVE-AI/">https://modeloriented.github.io/CVE-AI/</a></p>

<img data-src="images/01_valid.png" class="r-stretch"></section>
<section id="how-it-looked-in-the-past-33" class="slide level2">
<h2>How it looked in the past 3/3</h2>
<p>Edition 2023/24: <a href="https://github.com/MI2-Education/InterpretableMachineLearning2024">https://github.com/MI2-Education/InterpretableMachineLearning2024</a></p>

<img data-src="images/01_valid_B.png" class="r-stretch"></section>
<section id="key-information-about-this-edition" class="slide level2">
<h2>Key information about this edition</h2>
<p>This year Github: <a href="https://github.com/mim-uw/eXplainableMachineLearning-2025Z/blob/main/README.md">https://github.com/mim-uw/eXplainableMachineLearning-2025Z/</a></p>
<p>The classes are divided into:</p>
<ul>
<li>9+ lecture blocks (with special guests), where we will discuss various XAI and fairness techniques, but this is only an outline of a very rich and interesting field</li>
<li>one block with student presentations, here we will explore some recent XAI techniques</li>
<li>5 homeworks, they are related to the application of a selected XAI technique on a selected predictive problem</li>
<li>a written exam, where there will be tasks similar to those we will discuss during homework</li>
<li>we will mainly work on tabular data, although many of presented methods translate to problems in the area of computer vision, NLP, etc.</li>
</ul>
<p>Lecture/exercises/lab</p>
<ul>
<li>Lectures are focused on the theory behind explanations and presentations of projects (shared by both groups)</li>
<li>Exercises are for discussions about homeworks and projects</li>
</ul>
</section>
<section id="the-agenda" class="slide level2">
<h2>The agenda</h2>
<ul>
<li>2025-10-03 – Introduction to Model Science</li>
<li>2025-10-10 – Counterfactual explanations—what they are and how to find them, (guest lecture by Bartek Sobieski)</li>
<li>2025-10-10 – SHAP and friends</li>
<li>2025-10-17 – (online!!!) LIME and friends</li>
<li>2025-10-24 – SAE and other approaches to model control, (guest lecture by Vladimir Zaigrajew)</li>
<li>2025-10-31 – The inherent interpretability of prototype and concepts networks – solution or illusion? (guest lecture by Hubert Baniecki)</li>
<li>2025-11-07 – Partial Dependence, Ceteris Paribus and friends</li>
<li>2025-11-21 – VIP, gradients and friends</li>
<li>2025-11-28 – Fairness and biases</li>
<li>2025-12-05 (discussing projects)</li>
<li>2025-12-12 – PROJECT: showcase (in-person presentations)</li>
<li>2025-12-19 (discussing projects)</li>
<li>2026-01-09 – Student presentations of research papers</li>
<li>2026-01-16 (discussing projects)</li>
<li>2026-01-23 – PROJECT: final presentation (in-person presentations)</li>
</ul>
</section>
<section id="teaching-materials" class="slide level2">
<h2>Teaching materials</h2>
<div class="columns">
<div class="column" style="width:67%;">
<p>This course is based on “Explanatory Model Analysis” <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a></p>
<p><strong>Other sources that extend lectures</strong></p>
<ul>
<li>Fairness and machine learning <a href="https://fairmlbook.org/">https://fairmlbook.org/</a></li>
<li>An Introduction to Machine Learning Interpretability <a href="https://www.oreilly.com/library/view/an-introduction-to/9781492033158/">https://www.oreilly.com/library/view/an-introduction-to/9781492033158/</a></li>
<li>Interpretable Machine Learning. A Guide for Making Black Box Models Explainable <a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a></li>
<li>The Hitchhiker’s Guide to Responsible Machine Learning <a href="https://github.com/BetaAndBit/RML">https://github.com/BetaAndBit/RML</a></li>
</ul>
</div><div class="column" style="width:33%;">
<p><img data-src="images/01_ema.png"></p>
</div>
</div>
</section>
<section id="grades" class="slide level2">
<h2>Grades</h2>
<p>From different activities, you can get from 0 to 100(*) points.</p>
<p>51 points are needed to pass this course.</p>
<p>There are four key components.</p>
<ul>
<li>Project (obligatory)</li>
<li>Written exam (obligatory)</li>
<li>Homeworks (optional)</li>
<li>Presentation (optional)</li>
</ul>
<p>Detailed rules are presented here: <a href="https://github.com/mim-uw/eXplainableMachineLearning-2025/tree/main">https://github.com/mim-uw/eXplainableMachineLearning-2025/tree/main</a></p>
<p>(*) in fact one can get more, <code>5!</code> is waiting</p>
<div class="cell">
<style type="text/css">
.reveal {
  font-size: 24px;
  line-height: 1.6!important;
}
code {
  font-size: 18px!important;
  line-height: 1.2!important;
}
pre {
  line-height: 1.2!important;
}
</style>
</div>
</section></section>
<section>
<section id="model-explanations-why-should-you-care" class="title-slide slide level1 center">
<h1>Model explanations – Why should you care?</h1>

</section>
<section id="models-models-more-models" class="slide level2">
<h2>Models, models, more models …</h2>
<ul>
<li>For a long time in the media, data, machine learning and artificial intelligence were uncritically glorified</li>
<li>The dominant narrative was that almost every problem can be solved having enough data</li>
<li>Serious people were making statements like “there is no point in training radiologists, because they will be replaced by AI”</li>
<li>As with other bubbles, anything that is (star)AI(star) raised (unhealthy) attention</li>
<li>The media raced to announce what new problem AI had been solved</li>
</ul>
<p>
<img src="images/01_XAI_01.png" width="100%">
</p>
</section>
<section id="however-not-every-model-works" class="slide level2">
<h2>… however, not every model works …</h2>
<p>There is tremendous potential in AI, <strong>but</strong>:</p>
<ul>
<li>there is a growing list of examples in which, despite initial bursts of promise, AI systems did not perform as expected</li>
<li>good results on training data did not transfer to real-world data</li>
<li>systems performed in outright idiotic ways, even though they seemed to work very well during training</li>
<li>more and more people began to cooldown this hurra optimism and collect lists of epic failures of AI</li>
<li>at this point we could discuss various examples of spectacular failures of AI for the next two hours</li>
<li>see ,,Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy’’ by Cathy O’Neil for a very nice overview of these problems (audiobook lasts for over 6 hours)</li>
</ul>
</section>
<section id="ai-is-broken-17" class="slide level2">
<h2>AI is broken 1/7</h2>
<p>
<img src="images/01_issues_7.png" width="100%">
</p>
</section>
<section id="ai-is-broken-27" class="slide level2">
<h2>AI is broken 2/7</h2>
<p>
<img src="images/01_issues_6.png" width="100%">
</p>
</section>
<section id="ai-is-broken-37" class="slide level2">
<h2>AI is broken 3/7</h2>
<p>
<img src="images/01_issues_5.png" width="100%">
</p>
</section>
<section id="ai-is-broken-47" class="slide level2">
<h2>AI is broken 4/7</h2>
<p>
<img src="images/01_issues_4.png" width="100%">
</p>
</section>
<section id="ai-is-broken-57" class="slide level2">
<h2>AI is broken 5/7</h2>
<p>
<img src="images/01_issues_3.png" width="100%">
</p>
</section>
<section id="ai-is-broken-67" class="slide level2">
<h2>AI is broken 6/7</h2>
<p>
<img src="images/01_issues_1.png" width="100%">
</p>
</section>
<section id="ai-is-broken-77" class="slide level2">
<h2>AI is broken 7/7</h2>
<p>
<img src="images/01_issues_2.png" width="100%">
</p>
</section>
<section id="this-should-not-happen" class="slide level2">
<h2>This should not happen</h2>
<ul>
<li>How do we know what the model has learned? Maybe it bases decisions on some strange artifact?</li>
<li>This is not a made up possibility, in the example below the model’s decisions correlated strongly with the fact that there were captions in the lower left corner.</li>
<li>It turns out that in the learning data there was often a description in the lower left corner next to the horse pictures. Instead of learning to recognize the characteristics of horses, it is much easier to recognize the presence of text in the lower left corner.</li>
</ul>
<p>Read more: <a href="https://www.nature.com/articles/s41467-019-08987-4">Unmasking Clever Hans predictors and assessing what machines really learn</a></p>
<p>
</p><center>
<img src="images/01_CleverHans.png" width="100%">
</center>
<p></p>
</section></section>
<section>
<section id="model-explanations-how-to-get-there" class="title-slide slide level1 center">
<h1>Model explanations – How to get there</h1>

</section>
<section id="darpa-program-for-development-of-xai-methods" class="slide level2">
<h2>DARPA program for development of XAI methods</h2>
<ul>
<li>You may know DARPA for developing computer mouse (1964), GPS (1983), Internet – ARPANet (1969) or drones (1988).</li>
<li>In 2017, DARPA launched a major program to fund projects focused on Explainable Artificial Intelligence (XAI) in particular on AI-human collaboration. Research funded by this program is still ongoing and the program itself has contributed to the growing interest in XAI topics.</li>
<li>It is worth reading about the assumptions and concepts of this program, many of the ideas are still (after 5 years) valid and attractive research topics.</li>
</ul>
<p>Read more: <a href="https://www.darpa.mil/program/explainable-artificial-intelligence">https://www.darpa.mil/</a></p>
<p>
</p><center>
<img src="images/01_XAI_10.png" width="100%">
</center>
<p></p>
</section>
<section id="responsible-and-ethical-ai---the-business-response" class="slide level2">
<h2>Responsible and ethical AI - the business response</h2>
<ul>
<li>Interestingly, this line of research was very quickly get the interest of business.</li>
<li>On the websites of many companies dealing with AI-related products and services, you can find bookmarks with the topic of “Trustworthy AI”.</li>
<li>On the slide we have a few sites of companies producing software for (Auto)ML, namely H2O, we have consulting companies such as McKinsey, PWC, IBM, as well as product companies such as Samsung and Tensorflow.</li>
<li>Many companies are outdoing themselves in presenting their principals which include slogans such as Transparency, Fairness, Explaianbility. How can these slogans be realized?</li>
</ul>
<p>
</p><center>
<img src="images/01_XAI_11.png" width="100%">
</center>
<p></p>
</section>
<section id="the-right-to-an-explanation-in-europe" class="slide level2">
<h2>The right to an explanation in Europe</h2>
<p>From <a href="https://www.privacy-regulation.eu/en/recital-71-GDPR.htm">Recital 71 EU GDPR</a></p>
<p>,,(71) The data subject should have the right not to be subject to a decision, which may include a measure, evaluating personal aspects relating to him or her which is based solely on automated processing and which produces legal effects concerning him or her or similarly significantly affects him or her, such as automatic refusal of an online credit application or e-recruiting practices without any human intervention.</p>
<p>Such processing includes ‘profiling’ that consists of any form of automated processing of personal data evaluating the personal aspects relating to a natural person, in particular to analyse or predict aspects concerning the data subject’s performance at work, economic situation, health, personal preferences or interests, reliability or behaviour, location or movements, where it produces legal effects concerning him or her or similarly significantly affects him or her.</p>
<p>However, decision-making based on such processing, including profiling, should be allowed where expressly authorised by Union or Member State law to which the controller is subject, including for fraud and tax-evasion monitoring and prevention purposes conducted in accordance with the regulations, standards and recommendations of Union institutions or national oversight bodies and to ensure the security and reliability of a service provided by the controller, or necessary for the entering or performance of a contract between the data subject and a controller, or when the data subject has given his or her explicit consent.</p>
<p><strong>In any case, such processing should be subject to suitable safeguards, which should include specific information to the data subject and the right to obtain human intervention, to express his or her point of view, to obtain an explanation of the decision reached after such assessment and to challenge the decision</strong>.’’</p>
</section>
<section id="the-reaction-is-to-try-to-regulate-ai" class="slide level2">
<h2>The reaction is to try to regulate AI</h2>
<ul>
<li>For several years, the European Commission has been working on a so-called AI Act to regulate the use of automated algorithms within the European Union.</li>
<li>The act includes specific expectations related to the explainability of decisions supported by automated decision-making systems</li>
</ul>
<p>Read more: <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206">https://eur-lex.europa.eu</a></p>
<p>
<img src="images/01_XAI_07.png" width="100%">
</p>
</section></section>
<section>
<section id="model-explanations-what-we-will-talk-about" class="title-slide slide level1 center">
<h1>Model explanations – What we will talk about</h1>

</section>
<section id="two-views-on-xai-14" class="slide level2">
<h2>Two views on XAI 1/4</h2>
<p>
<img src="images/01_breiman.png" width="100%">
</p>
</section>
<section id="two-views-on-xai-24" class="slide level2">
<h2>Two views on XAI 2/4</h2>
<p>
<img src="images/01_two_blue.png" width="100%">
</p>
</section>
<section id="two-views-on-xai-34" class="slide level2">
<h2>Two views on XAI 3/4</h2>
<p>
<img src="images/01_two_red.png" width="100%">
</p>
</section>
<section id="two-views-on-xai-44" class="slide level2">
<h2>Two views on XAI 4/4</h2>
<p>
<img src="images/01_two.png" width="100%">
</p>
</section></section>
<section>
<section id="model-explanations-zoo" class="title-slide slide level1 center">
<h1>Model explanations – Zoo</h1>

</section>
<section id="introduction-to-model-science-12" class="slide level2">
<h2>Introduction to Model Science 1/2</h2>
<ul>
<li>Data Science and Model Science cover similar modeling areas but emphasize complementary perspectives.</li>
<li>Data Science focuses primarily on data. Around a given resource—typically a single well-defined dataset—many models are created to fit the data. Central to this perspective are the data themselves and challenges such as storage, acquisition visualization, and exploration.</li>
<li>Model Science perspective places the chosen model at the center of attention. The analysis of this model may involve multiple datasets (training, validation, monitoring, or out-of-domain), depending on the needs, but all are used primarily to study and understand the model.</li>
</ul>
<p>
</p><center>
<img src="images/01_model_science_2.png" width="60%">
</center>
<p></p>
</section>
<section id="introduction-to-model-science-22" class="slide level2">
<h2>Introduction to Model Science 2/2</h2>
<p>Four Pillars of Model Science</p>
<ul>
<li>Verification: does it work?</li>
<li>Explanation: how does it work?</li>
<li>Control: how it should work?</li>
<li>Interface: how to interact with it?</li>
</ul>
<p>
</p><center>
<img src="images/01_model_science_1.png" width="90%">
</center>
<p></p>
</section>
<section id="explanatory-model-analysis" class="slide level2">
<h2>Explanatory Model Analysis</h2>
<p>
<img src="images/01_ema_1.png" width="100%">
</p>
</section>
<section id="the-pyramid-of-explainability" class="slide level2">
<h2>The pyramid of explainability</h2>
<ul>
<li>In this class we will discuss several techniques for global and local analysis of the model.</li>
<li>Global analysis is concerned with the behavior of the model on the entire data</li>
<li>Local analysis deals with the model’s behavior on one/some observations</li>
<li>The subsequent techniques are complementary, creating an extended, increasingly detailed description of the model’s behavior</li>
</ul>
<p>
</p><center>
<img src="images/01_XAI.png" width="100%">
</center>
<p></p>
</section>
<section id="counterfactual-explanations" class="slide level2">
<h2>Counterfactual explanations</h2>
<p>What needs to be changed in the input data for the model to change its decisions?</p>
<p>
</p><center>
<img src="images/01_zoo_counterfactuals.png" width="60%">
</center>
<p></p>
<p>https://arxiv.org/abs/2404.12488e</p>
</section>
<section id="explanations-based-on-attributions" class="slide level2">
<h2>Explanations based on attributions</h2>
<p>Which parts of the input data (e.g., features) contribute to the final result of the model, and how?</p>
<p>
</p><center>
<img src="images/04_xai_bd_3.png" width="80%">
</center>
<p></p>
<p>https://ema.drwhy.ai/</p>
</section>
<section id="explanations-based-on-profiles" class="slide level2">
<h2>Explanations based on profiles</h2>
<p>How would the model’s response change if a specific input variable were changed?</p>
<p>
</p><center>
<img src="images/06_pdp_avg.png" width="80%">
</center>
<p></p>
<p>https://ema.drwhy.ai/</p>
</section>
<section id="model-control-and-mechanical-interpretability" class="slide level2">
<h2>Model control and mechanical interpretability</h2>
<p>Which parts of the neural network are responsible for specific output characteristics, and how can the internal processing of the model be influenced?</p>
<p>
</p><center>
<img src="images/01_zoo_sae.png" width="80%">
</center>
<p></p>
<p>https://arxiv.org/pdf/2309.08600</p>
</section>
<section id="prototype-and-concept-based-networks" class="slide level2">
<h2>Prototype and concept-based networks</h2>
<p>How to make models inherently more interpretable. How to ensure that they reason in a more human-like way?</p>
<p>
</p><center>
<img src="images/01_zoo_prototypes.png" width="60%">
</center>
<p></p>
<p>https://arxiv.org/abs/1806.10574o</p>
</section>
<section id="how-to-think-about-the-explainability-of-predictive-models" class="slide level2">
<h2>How to think about the explainability of predictive models</h2>
<p>When we think about the interpretability of models we usually distinguish three classes of methods</p>
<ul>
<li><strong>Interpretable by design,</strong> i.e.&nbsp;methods whose structure allows us to directly analyze how the prediction was formed. For different classes of models, explanations may look different, but they are directly based on model parameters. For linear models they are coefficients, for k-neighbors they are neighbors, for naive Bayes they are marginal distributions</li>
<li><strong>model specific,</strong> i.e.&nbsp;methods whose structure is complex but can be summarized or represented to better understand the relationship between input and output. The two most common classes of models with model-specific explanations are tree model committees (here we can summarize the tree structure) and neural networks (here we can usually summarize the flow of the signal through the network)</li>
<li><strong>model agnostic,</strong> i.e.&nbsp;methods to which this course is devoted, methods that assume nothing about the structure of the model and can be used for models with different structures. Moreover, they can be used to compare models with different structures.</li>
</ul>
<p>Read more: <a href="https://arxiv.org/pdf/2009.13248.pdf">arxiv.org/2009.13248</a></p>
<p>
</p><center>
<img src="images/01_XAI_12.png" width="100%">
</center>
<p></p>
</section>
<section id="there-is-no-one-size-fits-all-solution" class="slide level2">
<h2>There is no one-size-fits-all solution</h2>
<ul>
<li>We will talk about how to identify the needs of different stakeholders and match them with explanatory techniques</li>
<li>It’s still area that needs more active research, there’s a lot of talk about user needs, but the available methods are more aimed at model developers</li>
</ul>
<p>Read more: <a href="https://www.tandfonline.com/doi/abs/10.1080/01605682.2021.1922098">Transparency, Auditability and eXplainability of Machine Learning Models in Credit Scoring</a></p>
<p>
</p><center>
<img src="images/01_Transparency.png" width="100%">
</center>
<p></p>
</section>
<section id="shift-in-our-focus-statistics" class="slide level2">
<h2>Shift in our focus: Statistics</h2>
<ul>
<li>Statistical analysis of data most often assumes a great deal of knowledge about the phenomenon. Understanding the data allows to choose appropriate transformations, representations. Verification is oriented toward hypothesis testing, such as by p-values</li>
</ul>
<p>
</p><center>
<img src="images/01_shift1.png" width="100%">
</center>
<p></p>
</section>
<section id="shift-in-our-focus-machine-learning" class="slide level2">
<h2>Shift in our focus: Machine Learning</h2>
<ul>
<li>Machine learning puts a priority on optimizing the model, especially for performance. There is a lot of searching through the space of possible solutions here to find the best one</li>
<li>Knowledge of the phenomenon is no longer so important</li>
</ul>
<p>
</p><center>
<img src="images/01_shift2.png" width="100%">
</center>
<p></p>
</section>
<section id="shift-in-our-focus-human-oriented-ml" class="slide level2">
<h2>Shift in our focus: Human Oriented ML?</h2>
<ul>
<li>What’s next. If model building can be easily and quickly automated, in-depth model verification will become more important</li>
<li>This is where models are created seamlessly according to the needs of the user, and the user can focus on decisions supported by the models</li>
</ul>
<p>
</p><center>
<img src="images/01_shift3.png" width="100%">
</center>
<p></p>
</section></section>
<section id="take-home-message" class="title-slide slide level1 center">
<h1>Take-home message</h1>
<p><strong>Why interpretability is important?</strong></p>
<ul>
<li>Higher trust -&gt; <strong>higher adoption of ML/AI solutions</strong> that will support decision making process</li>
<li>May be <strong>required by auditors, regulators</strong>, law</li>
<li>New tool for model exploration -&gt; to <strong>gain new insights</strong> about the data/nature of some phenomenom</li>
<li>Gatekeeping role, human can <strong>control and/or block wrong decisions</strong> when knowing key reasons behind these decisions</li>
<li><strong>Debugg/improve data or models</strong>, identify wrong behaviour and help to plan actions to fix it</li>
<li><strong>Deeper diagnostic of models</strong>, validation against some domain knowledge, expectations or other values (like human rights -&gt; fairness)</li>
</ul>
<p><strong>Goals for this course:</strong></p>
<ul>
<li>Learn XAI techniques (model agnostic)</li>
<li>Learn the strengths and weaknesses of these techniques while doing a hands-on projects</li>
<li>Learn how to communicate explanations to (domain) experts and lay users</li>
</ul>
</section>

<section id="further-reading" class="title-slide slide level1 center">
<h1>Further reading</h1>
<ul>
<li><strong>The Mythos of Model Interpretability</strong> by <em>Zachary C. Lipton</em> <a href="https://arxiv.org/abs/1606.03490">https://arxiv.org/abs/1606.03490</a></li>
<li><strong>Wyjaśnialna sztuczna inteligencja: od metod do nowych spostrzeżeń</strong> by <em>Wojciech Samek</em> <a href="https://www.youtube.com/watch?v=PyL7u7iAIXs&amp;list=LL&amp;index=1&amp;t=6804s">https://www.youtube.com/watch?v=PyL7u7iAIXs&amp;list=LL&amp;index=1&amp;t=6804s</a></li>
</ul>

<img src="images/01_XAI.png" class="slide-logo r-stretch"><div class="footer footer-default">
<p>eXplainable AI – Introduction – MIM UW – 2025/26</p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="01_introduction_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="01_introduction_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="01_introduction_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="01_introduction_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>